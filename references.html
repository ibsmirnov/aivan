<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="author" content="Ivan Smirnov">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>References</title>
    <link rel="stylesheet" href="https://aivan.au/assets/style.css">
    <link rel="icon" type="image/png" href="https://aivan.au/assets/favicon/favicon-96x96.png" sizes="96x96" />
    <link rel="icon" type="image/svg+xml" href="https://aivan.au/assets/favicon/favicon.svg" />
    <link rel="shortcut icon" href="https://aivan.au/assets/favicon/favicon.ico" />
    <link rel="apple-touch-icon" sizes="180x180" href="https://aivan.au/assets/favicon/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-title" content="AIvan" />
    <link rel="manifest" href="https://aivan.au/assets/favicon/site.webmanifest" />
    <meta property="og:title" content="References" />
    <meta property="og:description" content="Getting Started with Generative AI in Research | Open Educational Resource" />
    <meta property="og:image" content="https://aivan.au/assets/images/banner.png" />
</head>
<body>
    <nav class="site-nav"><div class="nav-left"><a href="/">← Return Home</a></div><div class="nav-right"><span class="menu-items"><a href="about_the_author.html">About the author</a><span class="separator"> • </span><a href="course_philosophy.html">About the course</a></span></div></nav>
    <article class="content">
        <h1 id="references">References</h1>
<ol>
<li>Adamic et al. (2005). The political blogosphere and the 2004 US election: divided they blog. <em>Proceedings of the 3rd international workshop on Link discovery</em>, pp. 36–43</li>
<li>Alaboudi et al. (2021). An exploratory study of debugging episodes. <em>arXiv preprint arXiv:2105.02162</em></li>
<li>Argyle et al. (2023). Out of one, many: Using language models to simulate human samples. <em>Political Analysis</em>, vol. 31, no. 3, pp. 337–351</li>
<li>Baria et al. (2021). The brain is a computer is a brain: neuroscience‘s internal debate and the social significance of the Computational Metaphor. <em>arXiv preprint arXiv:2107.14042</em></li>
<li>Beisel et al. (2002). [RETRACTED] Histone methylation by the Drosophila epigenetic transcriptional regulator Ash1. <em>Nature</em>, vol. 419, no. 6909, pp. 857–862</li>
<li>Bender et al. (2020). Climbing towards NLU: On meaning, form, and understanding in the age of data. <em>Proceedings of the 58th annual meeting of the association for computational linguistics</em>, pp. 5185–5198</li>
<li>Berglund et al. (2023). The reversal curse: Llms trained on“ a is b” fail to learn“ b is a”. <em>arXiv preprint arXiv:2309.12288</em></li>
<li>Brown et al. (2020). Language models are few-shot learners. <em>Advances in neural information processing systems</em>, vol. 33, pp. 1877–1901</li>
<li>Cabanac et al. (2021). Tortured phrases: A dubious writing style emerging in science. Evidence of critical issues affecting established journals. <em>arXiv preprint arXiv:2107.06751</em></li>
<li>Callaham et al. (2002). Journal prestige, publication bias, and other characteristics associated with citation of published studies in peer-reviewed journals. <em>Jama</em>, vol. 287, no. 21, pp. 2847–2850</li>
<li>Castro Torres et al. (2022). North and South: Naming practices and the hidden dimension of global disparities in knowledge production. <em>Proceedings of the National Academy of Sciences</em>, vol. 119, no. 10, pp. e2119373119</li>
<li>Chollet and Francois (2019). On the measure of intelligence. <em>arXiv preprint arXiv:1911.01547</em></li>
<li>Deshpande et al. (2023). Toxicity in chatgpt: Analyzing persona-assigned language models. <em>arXiv preprint arXiv:2304.05335</em></li>
<li>Doshi et al. (2024). Generative AI enhances individual creativity but reduces the collective diversity of novel content. <em>Science Advances</em>, vol. 10, no. 28, pp. eadn5290</li>
<li>Drori et al. (2022). A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level. <em>Proceedings of the National Academy of Sciences</em>, vol. 119, no. 32, pp. e2123433119</li>
<li>Durmus et al. (2023). Towards measuring the representation of subjective global opinions in language models. <em>arXiv preprint arXiv:2306.16388</em></li>
<li>Dziri et al. (2024). Faith and fate: Limits of transformers on compositionality. <em>Advances in Neural Information Processing Systems</em>, vol. 36</li>
<li>Garcia et al. (2024). Artificial intelligence–generated draft replies to patient inbox messages. <em>JAMA Network Open</em>, vol. 7, no. 3, pp. e243201–e243201</li>
<li>Girotra et al. (2023). Ideas are dimes a dozen: Large language models for idea generation in innovation. <em>Available at SSRN 4526071</em></li>
<li>Ha et al. (2024). Organic or diffused: Can we distinguish human art from ai-generated images?. <em>Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security</em>, pp. 4822–4836</li>
<li>Hilbert et al. (2011). The world’s technological capacity to store, communicate, and compute information. <em>science</em>, vol. 332, no. 6025, pp. 60–65</li>
<li>Karras and Tero (2019). A Style-Based Generator Architecture for Generative Adversarial Networks. <em>arXiv preprint arXiv:1812.04948</em></li>
<li>Kong et al. (2023). Better zero-shot reasoning with role-play prompting. <em>arXiv preprint arXiv:2308.07702</em></li>
<li>Kotek et al. (2023). Gender bias and stereotypes in large language models. <em>Proceedings of the ACM collective intelligence conference</em>, pp. 12–24</li>
<li>Kumar et al. (2016). Ask me anything: Dynamic memory networks for natural language processing. <em>International conference on machine learning</em>, pp. 1378–1387</li>
<li>Köpf et al. (2024). Openassistant conversations-democratizing large language model alignment. <em>Advances in Neural Information Processing Systems</em>, vol. 36</li>
<li>Li et al. (2024). Artificial Intelligence awarded two Nobel Prizes for innovations that will shape the future of medicine. <em>NPJ Digital Medicine</em>, vol. 7, no. 1, pp. 336</li>
<li>Lightman et al. (2023). Let’s verify step by step. <em>arXiv preprint arXiv:2305.20050</em></li>
<li>M. Bran et al. (2024). Augmenting large language models with chemistry tools. <em>Nature Machine Intelligence</em>, pp. 1–11</li>
<li>Matter et al. (2024). Close to Human-Level Agreement: Tracing Journeys of Violent Speech in Incel Posts with GPT-4-Enhanced Annotations. <em>arXiv preprint arXiv:2401.02001</em></li>
<li>McAleese et al. (2024). Llm critics help catch llm bugs. <em>arXiv preprint arXiv:2407.00215</em></li>
<li>Morris et al. (n.d.). Levels of AGI for operationalizing progress on the path to AGI, arXiv, 2023. <em>arXiv preprint arXiv:2311.02462</em></li>
<li>Nasr et al. (2023). Scalable extraction of training data from (production) language models. <em>arXiv preprint arXiv:2311.17035</em></li>
<li>Park et al. (2023). Generative agents: Interactive simulacra of human behavior. <em>Proceedings of the 36th annual acm symposium on user interface software and technology</em>, pp. 1–22</li>
<li>Perkins et al. (2024). Genai detection tools, adversarial techniques and implications for inclusivity in higher education. <em>arXiv preprint arXiv:2403.19148</em></li>
<li>Porter et al. (2024). AI-generated poetry is indistinguishable from human-written poetry and is rated more favorably. <em>Scientific Reports</em>, vol. 14, no. 1, pp. 26133</li>
<li>Radford and Alec (2018). Improving language understanding by generative pre-training. </li>
<li>Sharma et al. (2023). Towards understanding sycophancy in language models. <em>arXiv preprint arXiv:2310.13548</em></li>
<li>Sharma et al. (2024). Facilitating self-guided mental health interventions through human-language model interaction: A case study of cognitive restructuring. <em>Proceedings of the 2024 CHI Conference on Human Factors in Computing Systems</em>, pp. 1–29</li>
<li>Si et al. (2024). Can llms generate novel research ideas? a large-scale human study with 100+ nlp researchers. <em>arXiv preprint arXiv:2409.04109</em></li>
<li>Sidorkin and Alexander M (2024). Embracing chatbots in higher education: the use of artificial intelligence in teaching, administration, and scholarship. </li>
<li>Sivak et al. (2019). Parents mention sons more often than daughters on social media. <em>Proceedings of the National Academy of Sciences</em>, vol. 116, no. 6, pp. 2039–2041</li>
<li>Stribling et al. (2005). Rooter: A methodology for the typical unification of access points and redundancy. </li>
<li>Unknown Author (2024). Delving into ChatGPT usage in academic writing through excess vocabulary. <em>arXiv preprint arXiv:2406.07016</em></li>
<li>Villalobos et al. (2024). Will we run out of data? Limits of LLM scaling based on human-generated data. <em>arXiv preprint arXiv:2211.04325</em>, vol. 3</li>
<li>Waswani et al. (2017). Attention is all you need. <em>NIPS</em></li>
<li>Wei et al. (2022). Chain-of-thought prompting elicits reasoning in large language models. <em>Advances in neural information processing systems</em>, vol. 35, pp. 24824–24837</li>
<li>West et al. (2023). THE GENERATIVE AI PARADOX:“What It Can Create, It May Not Understand”. <em>The Twelfth International Conference on Learning Representations</em></li>
<li>Wu et al. (2023). Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks. <em>arXiv preprint arXiv:2307.02477</em></li>
<li>Wu et al. (2024). [RETRACTED] Assessment of the efficacy of alkaline water in conjunction with conventional medication for the treatment of chronic gouty arthritis: A randomized controlled study. <em>Medicine</em>, vol. 103, no. 14, pp. e37589</li>
<li>Wuttke et al. (2024). AI Conversational Interviewing: Transforming Surveys with LLMs as Adaptive Interviewers. <em>arXiv preprint arXiv:2410.01824</em></li>
<li>Yin et al. (2024). Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance. <em>arXiv preprint arXiv:2402.14531</em></li>
<li>Zech et al. (2018). Confounding variables can degrade generalization performance of radiological deep learning models. <em>arXiv preprint arXiv:1807.00431</em></li>
<li>Zhang et al. (2024). [RETRACTED] The three-dimensional porous mesh structure of Cu-based metal-organic-framework-aramid cellulose separator enhances the electrochemical performance of lithium metal anode batteries. <em>Surfaces and Interfaces</em>, vol. 46, pp. 104081</li>
<li>Zheng et al. (2023). Is “A Helpful Assistant” the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts. <em>arXiv preprint arXiv:2311.10054</em>, vol. 8</li>
</ol>
    </article>
    <footer class="site-footer"><p>Copyright &copy; 2025 University of Technology Sydney <a href="https://creativecommons.org/licenses/by/4.0/">CC BY 4.0</a></p></footer>
    <script async defer src="https://scripts.withcabin.com/hello.js"></script>
</body>
</html>