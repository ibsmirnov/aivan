<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>References</title>
    <link rel="stylesheet" href="assets/style.css">
    <link rel="icon" type="image/png" href="assets/favicon/favicon-96x96.png" sizes="96x96" />
    <link rel="icon" type="image/svg+xml" href="assets/favicon/favicon.svg" />
    <link rel="shortcut icon" href="assets/favicon/favicon.ico" />
    <link rel="apple-touch-icon" sizes="180x180" href="assets/favicon/apple-touch-icon.png" />
    <meta name="apple-mobile-web-app-title" content="AIvan" />
    <link rel="manifest" href="assets/favicon/site.webmanifest" />
</head>
<body>
    <nav class="site-nav"><div class="nav-left"><a href="/">← Return Home</a></div><div class="nav-right"><span class="menu-items"><a href="about_the_author.html">About the author</a><span class="separator"> • </span><a href="course_philosophy.html">About the course</a></span></div></nav>
    <article class="content">
        <h1 id="references">References</h1>
<p>Here is a list of references that were used to create this course:</p>
<p>@article{hilbert2011world,
  title={The world’s technological capacity to store, communicate, and compute information},
  author={Hilbert, Martin and L{\‘o}pez, Priscila},
  journal={science},
  volume={332},
  number={6025},
  pages={60--65},
  year={2011},
  publisher={American Association for the Advancement of Science}
}</p>
<p>@inproceedings{waswani2017attention,
  title={Attention is all you need},
  author={Waswani, A and Shazeer, N and Parmar, N and Uszkoreit, J and Jones, L and Gomez, A and Kaiser, L and Polosukhin, I},
  booktitle={NIPS},
  year={2017}
}</p>
<p>@article{radford2018improving,
  title={Improving language understanding by generative pre-training},
  author={Radford, Alec},
  year={2018}
}</p>
<p>@article{morris2311levels,
  title={Levels of AGI for operationalizing progress on the path to AGI, arXiv, 2023},
  author={Morris, MR and Sohl-Dickstein, J and Fiedel, N and Warkentin, T and Dafoe, A and Faust, A and Farabet, C and Legg, S},
  journal={arXiv preprint arXiv:2311.02462}
}</p>
<p>@article{villalobos2024will,
  title={Will we run out of data? Limits of LLM scaling based on human-generated data},
  author={Villalobos, Pablo and Ho, Anson and Sevilla, Jaime and Besiroglu, Tamay and Heim, Lennart and Hobbhahn, Marius},
  journal={arXiv preprint arXiv:2211.04325},
  volume={3},
  year={2024},
  publisher={Jun}
}</p>
<p>@inproceedings{kumar2016ask,
  title={Ask me anything: Dynamic memory networks for natural language processing},
  author={Kumar, Ankit and Irsoy, Ozan and Ondruska, Peter and Iyyer, Mohit and Bradbury, James and Gulrajani, Ishaan and Zhong, Victor and Paulus, Romain and Socher, Richard},
  booktitle={International conference on machine learning},
  pages={1378--1387},
  year={2016},
  organization={PMLR}
}</p>
<p>@article{kopf2024openassistant,
  title={Openassistant conversations-democratizing large language model alignment},
  author={K{\“o}pf, Andreas and Kilcher, Yannic and von R{\”u}tte, Dimitri and Anagnostidis, Sotiris and Tam, Zhi Rui and Stevens, Keith and Barhoum, Abdullah and Nguyen, Duc and Stanley, Oliver and Nagyfi, Rich{\’a}rd and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}</p>
<p>@article{mcaleese2024llm,
  title={Llm critics help catch llm bugs},
  author={McAleese, Nat and Pokorny, Rai Michael and Uribe, Juan Felipe Ceron and Nitishinskaya, Evgenia and Trebacz, Maja and Leike, Jan},
  journal={arXiv preprint arXiv:2407.00215},
  year={2024}
}</p>
<p>@article{sharma2023towards,
  title={Towards understanding sycophancy in language models},
  author={Sharma, Mrinank and Tong, Meg and Korbak, Tomasz and Duvenaud, David and Askell, Amanda and Bowman, Samuel R and Cheng, Newton and Durmus, Esin and Hatfield-Dodds, Zac and Johnston, Scott R and others},
  journal={arXiv preprint arXiv:2310.13548},
  year={2023}
}</p>
<p>@article{drori2022neural,
  title={A neural network solves, explains, and generates university math problems by program synthesis and few-shot learning at human level},
  author={Drori, Iddo and Zhang, Sarah and Shuttleworth, Reece and Tang, Leonard and Lu, Albert and Ke, Elizabeth and Liu, Kevin and Chen, Linda and Tran, Sunny and Cheng, Newman and others},
  journal={Proceedings of the National Academy of Sciences},
  volume={119},
  number={32},
  pages={e2123433119},
  year={2022},
  publisher={National Acad Sciences}
}</p>
<p>@article{karras2019style,
  title={A Style-Based Generator Architecture for Generative Adversarial Networks},
  author={Karras, Tero},
  journal={arXiv preprint arXiv:1812.04948},
  year={2019}
}</p>
<p>@article{baria2021brain,
  title={The brain is a computer is a brain: neuroscience‘s internal debate and the social significance of the Computational Metaphor},
  author={Baria, Alexis T and Cross, Keith},
  journal={arXiv preprint arXiv:2107.14042},
  year={2021}
}</p>
<p>@inproceedings{bender2020climbing,
  title={Climbing towards NLU: On meaning, form, and understanding in the age of data},
  author={Bender, Emily M and Koller, Alexander},
  booktitle={Proceedings of the 58th annual meeting of the association for computational linguistics},
  pages={5185--5198},
  year={2020}
}</p>
<p>@article{dziri2024faith,
  title={Faith and fate: Limits of transformers on compositionality},
  author={Dziri, Nouha and Lu, Ximing and Sclar, Melanie and Li, Xiang Lorraine and Jiang, Liwei and Lin, Bill Yuchen and Welleck, Sean and West, Peter and Bhagavatula, Chandra and Le Bras, Ronan and others},
  journal={Advances in Neural Information Processing Systems},
  volume={36},
  year={2024}
}</p>
<p>@article{berglund2023reversal,
  title={The reversal curse: Llms trained on“ a is b” fail to learn“ b is a”},
  author={Berglund, Lukas and Tong, Meg and Kaufmann, Max and Balesni, Mikita and Stickland, Asa Cooper and Korbak, Tomasz and Evans, Owain},
  journal={arXiv preprint arXiv:2309.12288},
  year={2023}
}</p>
<p>@inproceedings{west2023generative,
  title={THE GENERATIVE AI PARADOX:“What It Can Create, It May Not Understand”},
  author={West, Peter and Lu, Ximing and Dziri, Nouha and Brahman, Faeze and Li, Linjie and Hwang, Jena D and Jiang, Liwei and Fisher, Jillian and Ravichander, Abhilasha and Chandu, Khyathi and others},
  booktitle={The Twelfth International Conference on Learning Representations},
  year={2023}
}</p>
<p>@article{chollet2019measure,
  title={On the measure of intelligence},
  author={Chollet, Fran{\c{c}}ois},
  journal={arXiv preprint arXiv:1911.01547},
  year={2019}
}</p>
<p>@article{wu2023reasoning,
  title={Reasoning or reciting? exploring the capabilities and limitations of language models through counterfactual tasks},
  author={Wu, Zhaofeng and Qiu, Linlu and Ross, Alexis and Aky{\"u}rek, Ekin and Chen, Boyuan and Wang, Bailin and Kim, Najoung and Andreas, Jacob and Kim, Yoon},
  journal={arXiv preprint arXiv:2307.02477},
  year={2023}
}</p>
<p>@article{zheng2023helpful,
  title={Is “A Helpful Assistant” the Best Role for Large Language Models? A Systematic Evaluation of Social Roles in System Prompts},
  author={Zheng, Mingqian and Pei, Jiaxin and Jurgens, David},
  journal={arXiv preprint arXiv:2311.10054},
  volume={8},
  year={2023}
}</p>
<p>@article{deshpande2023toxicity,
  title={Toxicity in chatgpt: Analyzing persona-assigned language models},
  author={Deshpande, Ameet and Murahari, Vishvak and Rajpurohit, Tanmay and Kalyan, Ashwin and Narasimhan, Karthik},
  journal={arXiv preprint arXiv:2304.05335},
  year={2023}
}</p>
<p>@article{kong2023better,
  title={Better zero-shot reasoning with role-play prompting},
  author={Kong, Aobo and Zhao, Shiwan and Chen, Hao and Li, Qicheng and Qin, Yong and Sun, Ruiqi and Zhou, Xin and Wang, Enzhi and Dong, Xiaohang},
  journal={arXiv preprint arXiv:2308.07702},
  year={2023}
}</p>
<p>@article{wei2022chain,
  title={Chain-of-thought prompting elicits reasoning in large language models},
  author={Wei, Jason and Wang, Xuezhi and Schuurmans, Dale and Bosma, Maarten and Xia, Fei and Chi, Ed and Le, Quoc V and Zhou, Denny and others},
  journal={Advances in neural information processing systems},
  volume={35},
  pages={24824--24837},
  year={2022}
}</p>
<p>@article{lightman2023let,
  title={Let’s verify step by step},
  author={Lightman, Hunter and Kosaraju, Vineet and Burda, Yura and Edwards, Harri and Baker, Bowen and Lee, Teddy and Leike, Jan and Schulman, John and Sutskever, Ilya and Cobbe, Karl},
  journal={arXiv preprint arXiv:2305.20050},
  year={2023}
}</p>
<p>@article{brown2020language,
  title={Language models are few-shot learners},
  author={Brown, Tom and Mann, Benjamin and Ryder, Nick and Subbiah, Melanie and Kaplan, Jared D and Dhariwal, Prafulla and Neelakantan, Arvind and Shyam, Pranav and Sastry, Girish and Askell, Amanda and others},
  journal={Advances in neural information processing systems},
  volume={33},
  pages={1877--1901},
  year={2020}
}</p>
<p>@article{yin2024should,
  title={Should We Respect LLMs? A Cross-Lingual Study on the Influence of Prompt Politeness on LLM Performance},
  author={Yin, Ziqi and Wang, Hao and Horio, Kaito and Kawahara, Daisuke and Sekine, Satoshi},
  journal={arXiv preprint arXiv:2402.14531},
  year={2024}
}
25 above, 12 below section 2 not done
add to course philosophy
update literature review</p>
<p>@article{kobak2024delving,
  title={Delving into ChatGPT usage in academic writing through excess vocabulary},
  author={Kobak, Dmitry and Gonz{\‘a}lez-M{\’a}rquez, Rita and Horv{\‘a}t, Em{\H{o}}ke-{\’A}gnes and Lause, Jan},
  journal={arXiv preprint arXiv:2406.07016},
  year={2024}
}</p>
<p>@article{zhang2024three,
  title={[RETRACTED] The three-dimensional porous mesh structure of Cu-based metal-organic-framework-aramid cellulose separator enhances the electrochemical performance of lithium metal anode batteries},
  author={Zhang, Manshu and Wu, Liming and Yang, Tao and Zhu, Bing and Liu, Yangai},
  journal={Surfaces and Interfaces},
  volume={46},
  pages={104081},
  year={2024},
  publisher={Elsevier}
}</p>
<p>@article{wu2024assessment,
  title={[RETRACTED] Assessment of the efficacy of alkaline water in conjunction with conventional medication for the treatment of chronic gouty arthritis: A randomized controlled study},
  author={Wu, Yong and Pang, Shuwen and Guo, Jing and Yang, Jie and Ou, Rui},
  journal={Medicine},
  volume={103},
  number={14},
  pages={e37589},
  year={2024},
  publisher={LWW}
}</p>
<p>@article{cabanac2021tortured,
  title={Tortured phrases: A dubious writing style emerging in science. Evidence of critical issues affecting established journals},
  author={Cabanac, Guillaume and Labb{\'e}, Cyril and Magazinov, Alexander},
  journal={arXiv preprint arXiv:2107.06751},
  year={2021}
}</p>
<p>@article{stribling2021rooter,
  title={Rooter: A methodology for the typical unification of access points and redundancy},
  author={Stribling, Jeremy and Aguayo, Daniel and Krohn, Max},
  year={2005}
}</p>
<p>@article{perkins2024genai,
  title={Genai detection tools, adversarial techniques and implications for inclusivity in higher education},
  author={Perkins, Mike and Roe, Jasper and Vu, Binh H and Postma, Darius and Hickerson, Don and McGaughran, James and Khuat, Huy Q},
  journal={arXiv preprint arXiv:2403.19148},
  year={2024}
}</p>
<p>@inproceedings{ha2024organic,
  title={Organic or diffused: Can we distinguish human art from ai-generated images?},
  author={Ha, Anna Yoo Jeong and Passananti, Josephine and Bhaskar, Ronik and Shan, Shawn and Southen, Reid and Zheng, Haitao and Zhao, Ben Y},
  booktitle={Proceedings of the 2024 on ACM SIGSAC Conference on Computer and Communications Security},
  pages={4822--4836},
  year={2024}
}</p>
<p>@article{porter2024ai,
  title={AI-generated poetry is indistinguishable from human-written poetry and is rated more favorably},
  author={Porter, Brian and Machery, Edouard},
  journal={Scientific Reports},
  volume={14},
  number={1},
  pages={26133},
  year={2024},
  publisher={Nature Publishing Group UK London}
}</p>
<p>@article{nasr2023scalable,
  title={Scalable extraction of training data from (production) language models},
  author={Nasr, Milad and Carlini, Nicholas and Hayase, Jonathan and Jagielski, Matthew and Cooper, A Feder and Ippolito, Daphne and Choquette-Choo, Christopher A and Wallace, Eric and Tram{`e}r, Florian and Lee, Katherine},
  journal={arXiv preprint arXiv:2311.17035},
  year={2023}
}</p>
<p>@inproceedings{kotek2023gender,
  title={Gender bias and stereotypes in large language models},
  author={Kotek, Hadas and Dockum, Rikker and Sun, David},
  booktitle={Proceedings of the ACM collective intelligence conference},
  pages={12--24},
  year={2023}
}</p>
<p>@article{durmus2023towards,
  title={Towards measuring the representation of subjective global opinions in language models},
  author={Durmus, Esin and Nyugen, Karina and Liao, Thomas I and Schiefer, Nicholas and Askell, Amanda and Bakhtin, Anton and Chen, Carol and Hatfield-Dodds, Zac and Hernandez, Danny and Joseph, Nicholas and others},
  journal={arXiv preprint arXiv:2306.16388},
  year={2023}
}</p>
<p>@book{sidorkin2024embracing,
  title={Embracing chatbots in higher education: the use of artificial intelligence in teaching, administration, and scholarship},
  author={Sidorkin, Alexander M},
  year={2024},
  publisher={Taylor \&amp; Francis}
}</p>
    </article>
    <footer class="site-footer"><p>Copyright &copy; 2025 University of Technology Sydney</p></footer>
</body>
</html>